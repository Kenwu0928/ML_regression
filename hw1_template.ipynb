{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s109000114/ML_regression/blob/main/hw1_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Te27fi-0pP"
      },
      "source": [
        "# **HW1: Regression**\n",
        "In *assignment 1*, you need to finish:\n",
        "\n",
        "1.  Basic Part: Implement two regression models to predict the Systolic blood pressure (SBP) of a patient. You will need to implement **both Matrix Inversion and Gradient Descent**.\n",
        "\n",
        "\n",
        "> *   Step 1: Split Data\n",
        "> *   Step 2: Preprocess Data\n",
        "> *   Step 3: Implement Regression\n",
        "> *   Step 4: Make Prediction\n",
        "> *   Step 5: Train Model and Generate Result\n",
        "\n",
        "2.  Advanced Part: Implement one regression model to predict the SBP of multiple patients in a different way than the basic part. You can choose **either** of the two methods for this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDdnos-4uUv"
      },
      "source": [
        "# **1. Basic Part (55%)**\n",
        "In the first part, you need to implement the regression to predict SBP from the given DBP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EVqWlB-DTF"
      },
      "source": [
        "## 1.1 Matrix Inversion Method (25%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_mi.csv**\n",
        "*   Print your coefficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCR7vk9BFkf"
      },
      "source": [
        "### *Import Packages*\n",
        "\n",
        "> Note: You **cannot** import any other package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "HL5XjqFf4wSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWjrzi0dMPz"
      },
      "source": [
        "### *Global attributes*\n",
        "Define the global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "EWLDPOlHBbcK"
      },
      "outputs": [],
      "source": [
        "training_dataroot = 'hw1_basic_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "testing_dataroot = 'hw1_basic_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "output_dataroot = 'hw1_basic_mi.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsFC-cvqIcYK"
      },
      "source": [
        "You can add your own global attributes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "OUbS2BEgcut6"
      },
      "outputs": [],
      "source": [
        "basic_trained = np.array([])\n",
        "basic_validate = np.array([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoRFoQjBW5S"
      },
      "source": [
        "### *Load the Input File*\n",
        "First, load the basic input file **hw1_basic_training.csv** and **hw1_basic_testing.csv**\n",
        "\n",
        "Input data would be stored in *training_datalist* and *testing_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "dekR1KnqBtI6"
      },
      "outputs": [],
      "source": [
        "# Read hw1_basic_training.csv\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "  training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "# Read hw1_basic_testing.csv\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "  testing_datalist = np.array(list(csv.reader(csvfile)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prints the number of rows\n",
        "print(training_datalist.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fqv-wFn4c-_",
        "outputId": "59481903-0be3-466c-d016-975090dd0fe3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_datalist[1]) # header\n",
        "print(training_datalist[1]) # first row of data\n",
        "print(training_datalist[373])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVnFRqX84k-2",
        "outputId": "18537cc0-7060-4c48-9148-48d3378ad17d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['92' '142']\n",
            "['92' '142']\n",
            "['94' '154']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kYPuikLCFx4"
      },
      "source": [
        "### *Implement the Regression Model*\n",
        "\n",
        "> Note: It is recommended to use the functions we defined, you can also define your own functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWwdx06JNEYs"
      },
      "source": [
        "#### Step 1: Split Data\n",
        "Split data in *training_datalist* into training dataset and validation dataset\n",
        "* Validation dataset is used to validate your own model without the testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "USDciENcB-5F"
      },
      "outputs": [],
      "source": [
        "def SplitData():\n",
        "  # seperate basic input as training and validation set\n",
        "  global basic_trained, basic_validate\n",
        "  basic_trained = np.array(training_datalist[1:343])\n",
        "  basic_validate = np.array(training_datalist[343:])\n",
        "  # print(basic_trained[:,0]) # column 0 -> dbp, from the first row to the last row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-3Qln4aNgVy"
      },
      "source": [
        "#### Step 2: Preprocess Data\n",
        "Handle the unreasonable data\n",
        "> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "XXvW1n_5NkQ5"
      },
      "outputs": [],
      "source": [
        "def findBound(data):\n",
        "  dataMean = np.mean(data)\n",
        "  dataStd = np.std(data)\n",
        "  dataUpper = dataMean + 2 * dataStd\n",
        "  dataLower = dataMean - 2 * dataStd\n",
        "  # print(dataMean)\n",
        "  # print(dataStd)\n",
        "  return dataUpper, dataLower\n",
        "\n",
        "def removeOutlier(data):\n",
        "\n",
        "  # print(data[:][0])\n",
        "  # tmp = data[:,0]\n",
        "  featureUpper, featureLower = findBound(data[:,0])\n",
        "  outputUpper, outputLower = findBound(data[:,1])\n",
        "  # print(\"featureUpper: \", featureUpper)\n",
        "  # print(\"featureLower\", featureLower)\n",
        "  # print(\"outputLower\", outputLower)\n",
        "  # print(\"outputUpper: \", outputUpper)\n",
        "\n",
        "  condition = (data[:, 0] < featureUpper) & (data[:, 0] > featureLower) \\\n",
        "          & (data[:, 1] < outputUpper) & (data[:, 1] > outputLower)\n",
        "\n",
        "  remainingData = data[condition]\n",
        "\n",
        "  return remainingData\n",
        "\n",
        "def PreprocessData():\n",
        "  global basic_trained, basic_validate\n",
        "  basic_trained = basic_trained.astype('float64')\n",
        "  basic_validate = basic_validate.astype('float64')\n",
        "\n",
        "  basic_trained = removeOutlier(basic_trained)\n",
        "  # print('basic_trained : ')\n",
        "  # print(basic_trained)\n",
        "\n",
        "  basic_validate = removeOutlier(basic_validate)\n",
        "  # print('basic_validate : ')\n",
        "  # print(basic_validate)\n",
        "\n",
        "# PreprocessData()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLpJmQUN3V6"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Matrix Inversion to finish this part\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx9n1_23N8C0"
      },
      "outputs": [],
      "source": [
        "# def MatrixInversion():\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRNFwyN8xd"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "Make prediction of testing dataset and store the value in *output_datalist*\n",
        "The final *output_datalist* should look something like this\n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "EKlDIC2-N_lk"
      },
      "outputs": [],
      "source": [
        "def MakePrediction():\n",
        "  global basic_trained, basic_validate\n",
        "\n",
        "  tmp = np.ones((basic_trained[:,0].reshape(-1, 1).shape[0], 1))\n",
        "  basicTrainedDbp = np.concatenate((tmp, basic_trained[:,0].reshape(-1, 1)), axis=1) # two dimensional\n",
        "  # print(basicTrainedDbp)\n",
        "  inverseBasicTrainedDbp = np.linalg.pinv(basicTrainedDbp)\n",
        "  ans = np.dot(inverseBasicTrainedDbp, basic_trained[:,1])\n",
        "  # print(ans)\n",
        "  return ans[1], ans[0]\n",
        "\n",
        "# MakePrediction()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write output to output_datalist"
      ],
      "metadata": {
        "id": "YW_iBs23dFfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WriteOutputToList():\n",
        "  global basic_trained, basic_validate, output_datalist, testing_datalist\n",
        "  float_testing_datalist = testing_datalist[1:,].astype('float64')\n",
        "  for i in float_testing_datalist[:, 0]:\n",
        "    output_datalist.append([round(48.50083248 + i * 0.97811663)])\n",
        "  # print(output_datalist)"
      ],
      "metadata": {
        "id": "_hehLDRldcCr"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCd0Z6izOCwq"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "iCL92EPKOFIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9704824a-967d-46d0-ec74-5e32082a37cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9781166254259199 48.500832478436806\n"
          ]
        }
      ],
      "source": [
        "SplitData()\n",
        "PreprocessData()\n",
        "co1, co2 = MakePrediction()\n",
        "print(f'{co1} {co2}')\n",
        "WriteOutputToList()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test validation set MAPE\n",
        "def testValidationMape():\n",
        "  global basic_trained, basic_validate\n",
        "  tmpAns = []\n",
        "  mapeVal = 0\n",
        "  for i in basic_validate[:, 0]:\n",
        "    tmpAns.append(48.48096161325025 + i * 0.9789982101532443)\n",
        "    # print(48.50083248 + i * 0.9789982101532443)\n",
        "\n",
        "  for i in range(len(tmpAns)):\n",
        "    mapeVal += abs((basic_validate[i, 1] - round(tmpAns[i])) / basic_validate[i, 1])\n",
        "  print(mapeVal / len(tmpAns) * 100)\n",
        "  # print(mapeVal / range(len(tmpAns)))\n",
        "\n",
        "testValidationMape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaRMojJpxhmq",
        "outputId": "4996680f-2c5e-41ed-be16-8f08ee25cf05"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.227110740318262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Jhd8wAOk3D"
      },
      "source": [
        "### *Write the Output File*\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "tYQVYLlKOtDB"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3WOhglA9ML"
      },
      "source": [
        "## 1.2 Gradient Descent Method (30%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_gd.csv**\n",
        "*   Output your coefficient update in a csv file **hw1_basic_coefficient.csv**\n",
        "*   Print your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkMqa_xjXhEv"
      },
      "source": [
        "### *Global attributes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "wNZtRWUeXpEu"
      },
      "outputs": [],
      "source": [
        "output_dataroot = 'hw1_basic_gd.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "coefficient_output_dataroot = 'hw1_basic_coefficient.csv'\n",
        "\n",
        "# training_datalist =  [] # Training datalist, saved as numpy array\n",
        "# testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "gd_output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']\n",
        "\n",
        "coefficient_output = [] # Your coefficient update during gradient descent\n",
        "                   # Should be a (number of iterations * number_of coefficient) matrix\n",
        "                   # The format of each row should be ['w0', 'w1', ...., 'wn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5DeHxdLdai3"
      },
      "source": [
        "Your own global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "_2IO5tYSdaFd"
      },
      "outputs": [],
      "source": [
        "ans_coe = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVBLT1aqXuW0"
      },
      "source": [
        "### *Implement the Regression Model*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecPWpcOnXhCZ"
      },
      "source": [
        "#### Step 1: Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PEf_qGvYHu0"
      },
      "outputs": [],
      "source": [
        "# def SplitData():\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpSoPDPKX56w"
      },
      "source": [
        "#### Step 2: Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLTXOWRwYHiS"
      },
      "outputs": [],
      "source": [
        "# def PreprocessData():\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV_y82gXX6a-"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Gradient Descent to finish this part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "-635Ee00YHTE"
      },
      "outputs": [],
      "source": [
        "def loss(params):\n",
        "  global basic_trained, basic_validate\n",
        "  basic_trained_feature = basic_trained[:,0]\n",
        "  basic_trained_output = basic_trained[:,1]\n",
        "  num_samples = len(basic_trained_feature)\n",
        "  loss_sum = 0.0\n",
        "\n",
        "  for x, y in zip(basic_trained_feature,basic_trained_output):\n",
        "    y_hat = np.dot(params, np.array([1.0, x]))\n",
        "    loss_sum += (y_hat - y) ** 2\n",
        "\n",
        "  loss = loss_sum / (num_samples * 2)\n",
        "  return loss\n",
        "\n",
        "def GradientDescent(params, alpha, max_iter):\n",
        "  global basic_trained, basic_validate, coefficient_output\n",
        "  basic_trained_feature = basic_trained[:,0]\n",
        "  basic_trained_output = basic_trained[:,1]\n",
        "  iteration = 0\n",
        "  num_samples = len(basic_trained_feature)\n",
        "  cost = np.zeros(max_iter)\n",
        "  params_store = np.zeros([2, max_iter])\n",
        "\n",
        "  while iteration < max_iter:\n",
        "    cost[iteration] = loss(params) # just for debugging\n",
        "    params_store[:, iteration] = params\n",
        "\n",
        "    # print('======================')\n",
        "    # print(f'iteratin: {iteration}')\n",
        "    # print(f'cost: {cost[iteration]}')\n",
        "\n",
        "    # print('======================')\n",
        "    # print(f'iteratin: {iteration}')\n",
        "    # print(f'coefficients: {params[0]} {params[1]}')\n",
        "    coefficient_output.append([params[0], params[1]])\n",
        "\n",
        "    for x, y in zip(basic_trained_feature, basic_trained_output):\n",
        "      y_hat = np.dot(params, np.array([1.0, x]))\n",
        "      gradient = np.array([1.0, x]) * (y - y_hat)\n",
        "      params += alpha * gradient/num_samples\n",
        "\n",
        "    iteration += 1\n",
        "  print(coefficient_output)\n",
        "  return coefficient_output[-1]\n",
        "  # return params\n",
        "  # return params, cost, params_store\n",
        "\n",
        "# sm = 1000\n",
        "# a = 47.0\n",
        "# b = 0.6\n",
        "# fa = 0.0\n",
        "# fb = 0.0\n",
        "\n",
        "# while a < 50:\n",
        "#   b = 0.6\n",
        "#   while b < 1.0:\n",
        "#     tmp = GradientDescent(np.array([a, b]), 0.0001, 50)\n",
        "#     print('tmp: ', tmp)\n",
        "#     if tmp < sm:\n",
        "#       sm = tmp\n",
        "#       fa = a\n",
        "#       fb = b\n",
        "#     b += 0.1\n",
        "#   a += 0.1\n",
        "\n",
        "# print('sm: ', sm)\n",
        "# print('a: ',a)\n",
        "# print('b: ',b)\n",
        "\n",
        "# GradientDescent(np.array([48.48, 0.9]), 0.0001, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLuPxs2ZX21S"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "\n",
        "Make prediction of testing dataset and store the values in *output_datalist*\n",
        "The final *output_datalist* should look something like this\n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP\n",
        "\n",
        "Remember to also store your coefficient update in *coefficient_output*\n",
        "The final *coefficient_output* should look something like this\n",
        "> [ [1, 0, 3, 5], ... , [0.1, 0.3, 0.2, 0.5] ] where each row contains the [w0, w1, ..., wn] of your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "8pnNDlQeYGtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be21d5a-25d5-4374-e399-2c218b97310c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[48.48, 0.9], [48.48047038081597, 0.9391990068695709], [48.48070750272228, 0.9589474576963941], [48.480827108831846, 0.9688967219205958], [48.48088751050414, 0.9739091577136758], [48.48091808499122, 0.9764344202395595], [48.48093363254752, 0.977706645325039], [48.480941609538526, 0.9783475903755651], [48.48094577247966, 0.9786704966591097], [48.480948013902946, 0.9788331750696015], [48.480949287265425, 0.9789151307067459], [48.48095007291886, 0.9789564182253396], [48.48095061286413, 0.9789772171531941], [48.48095102902143, 0.9789876939327589], [48.480951382814, 0.9789929704158935], [48.48095170518689, 0.9789956269906354], [48.480952011730146, 0.9789969636560084], [48.480952310298186, 0.9789976353512854], [48.48095260484796, 0.9789979720347518], [48.48095289737304, 0.9789981399393343], [48.48095318887774, 0.9789982228131482], [48.48095347986808, 0.9789982628484809], [48.48095377059885, 0.9789982813017977], [48.48095406119863, 0.9789982888821032], [48.48095435173204, 0.9789982909845912], [48.480954642231644, 0.97899829032736], [48.480954932713935, 0.9789982882797869], [48.48095522318712, 0.9789982855317639], [48.480955513655395, 0.9789982824308583], [48.480955804120896, 0.9789982791521749], [48.48095609458462, 0.9789982757839294], [48.48095638504721, 0.9789982723705677], [48.48095667550887, 0.97899826893448], [48.48095696596968, 0.9789982654869471], [48.48095725642978, 0.9789982620336525], [48.48095754688919, 0.9789982585774571], [48.48095783734793, 0.978998255119806], [48.48095812780598, 0.9789982516614246], [48.48095841826331, 0.9789982482026793], [48.48095870871998, 0.9789982447437557], [48.48095899917596, 0.9789982412847458], [48.48095928963131, 0.9789982378256963], [48.48095958008603, 0.97899823436663], [48.48095987054009, 0.9789982309075602], [48.48096016099345, 0.9789982274484917], [48.48096045144612, 0.9789982239894284], [48.480960741898166, 0.9789982205303714], [48.480961032349555, 0.9789982170713202], [48.480961322800226, 0.9789982136122786], [48.48096161325025, 0.9789982101532443]]\n"
          ]
        }
      ],
      "source": [
        "def MakePrediction():\n",
        "  global ans_coe\n",
        "  ans_coe = GradientDescent(np.array([48.48, 0.9]), 0.0001, 50)\n",
        "\n",
        "MakePrediction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScbxxMAYAgZ"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "90EisOc7YG-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb3c21e-51e3-4eb9-82c9-48dfd24a1f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9789982101532443 48.48096161325025\n"
          ]
        }
      ],
      "source": [
        "# tmp_testing_datalist = testing_datalist[1:,].astype('float64')\n",
        "# for i in tmp_testing_datalist[:, 0]:\n",
        "#   gd_output_datalist.append([round(48.48096161325025 + i * 0.9789982101532443)])\n",
        "# print(gd_output_datalist)\n",
        "\n",
        "# print('ax + b')\n",
        "print(f'{ans_coe[1]} {ans_coe[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1DpV_HcYFpl"
      },
      "source": [
        "### *Write the Output File*\n",
        "\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "**Write the coefficient update to csv**\n",
        "> Format: 'w0', 'w1', ..., 'wn'\n",
        ">*   The number of columns is based on your number of coefficient\n",
        ">*   The number of row is based on your number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "NLSHgpDvDXNI"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in gd_output_datalist:\n",
        "    writer.writerow(row)\n",
        "\n",
        "with open(coefficient_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in coefficient_output:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4408qg4xMQ"
      },
      "source": [
        "# **2. Advanced Part (40%)**\n",
        "In the second part, you need to implement the regression in a different way than the basic part to help your predictions of multiple patients SBP.\n",
        "\n",
        "You can choose **either** Matrix Inversion or Gradient Descent method.\n",
        "\n",
        "The training data will be in **hw1_advanced_training.csv** and the testing data will be in **hw1_advanced_testing.csv**.\n",
        "\n",
        "Output your prediction in **hw1_advanced.csv**\n",
        "\n",
        "Notice:\n",
        "> You cannot import any other package other than those given\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNdwprN8YnJt"
      },
      "source": [
        "### Input the training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "v66HUClZcxaE"
      },
      "outputs": [],
      "source": [
        "advance_training_dataroot = 'hw1_advanced_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "advance_testing_dataroot = 'hw1_advanced_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "advance_output_dataroot = 'hw1_advanced.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "# advance_training_datalist =  [] # Training datalist, saved as numpy array\n",
        "# advance_testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "advance_output_datalist =  [] # Your prediction, should be 220 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']\n",
        "# advance_trained = np.array([])\n",
        "# advance_validate = np.array([])\n",
        "\n",
        "# seperate_id_data = pd.DataFrame()\n",
        "# seperate_train = pd.DataFrame()\n",
        "# seperate_validate = pd.DataFrame()\n",
        "\n",
        "id_11526383 = pd.DataFrame()\n",
        "id_11526383_train = pd.DataFrame()\n",
        "id_11526383_validate = pd.DataFrame()\n",
        "\n",
        "id_12923910 = pd.DataFrame()\n",
        "id_12923910_train = pd.DataFrame()\n",
        "id_12923910_validate = pd.DataFrame()\n",
        "\n",
        "id_14699420 = pd.DataFrame()\n",
        "id_14699420_train = pd.DataFrame()\n",
        "id_14699420_validate = pd.DataFrame()\n",
        "\n",
        "id_15437705 = pd.DataFrame()\n",
        "id_15437705_train = pd.DataFrame()\n",
        "id_15437705_validate = pd.DataFrame()\n",
        "\n",
        "id_15642911 = pd.DataFrame()\n",
        "id_15642911_train = pd.DataFrame()\n",
        "id_15642911_validate = pd.DataFrame()\n",
        "\n",
        "id_16298357 = pd.DataFrame()\n",
        "id_16298357_train = pd.DataFrame()\n",
        "id_16298357_validate = pd.DataFrame()\n",
        "\n",
        "id_17331999 = pd.DataFrame()\n",
        "id_17331999_train = pd.DataFrame()\n",
        "id_17331999_validate = pd.DataFrame()\n",
        "\n",
        "id_17593883 = pd.DataFrame()\n",
        "id_17593883_train = pd.DataFrame()\n",
        "id_17593883_validate = pd.DataFrame()\n",
        "\n",
        "id_18733920 = pd.DataFrame()\n",
        "id_18733920_train = pd.DataFrame()\n",
        "id_18733920_validate = pd.DataFrame()\n",
        "\n",
        "id_18791093 = pd.DataFrame()\n",
        "id_18791093_train = pd.DataFrame()\n",
        "id_18791093_validate = pd.DataFrame()\n",
        "\n",
        "id_19473413 = pd.DataFrame()\n",
        "id_19473413_train = pd.DataFrame()\n",
        "id_19473413_validate = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOIzdAWxYnJt"
      },
      "source": [
        "### Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWv3kxt7YnJt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# with open(advance_training_dataroot, newline='') as csvfile:\n",
        "#   advance_training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "# with open(advance_testing_dataroot, newline='') as csvfile:\n",
        "#   advance_testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "###### read hw1_advanced_training.csv and group data by subject_id\n",
        "training_df = pd.read_csv(advance_training_dataroot)\n",
        "training_df = training_df.dropna()\n",
        "training_df = training_df.reset_index(drop=True)\n",
        "grouped = training_df.groupby('subject_id')\n",
        "training_df = [group for _, group in grouped]\n",
        "training_df = {value: group for value, group in grouped}\n",
        "\n",
        "# for index, row in training_df[11526383].iterrows():\n",
        "#     print(row[1])\n",
        "\n",
        "for index in range(2, len(id_11526383)):\n",
        "  current_row = id_11526383.iloc[index]\n",
        "  last_row = id_11526383.iloc[index - 1]\n",
        "  last_2nd_row = id_11526383.iloc[index - 2]\n",
        "  # print(current_row, last_row, last_2nd_row)\n",
        "\n",
        "# print(id_11526383.iloc[4][3]) # important info\n",
        "\n",
        "##### read hw1_advanced_testing.csv and group data by subject_id\n",
        "testing_df = pd.read_csv(advance_testing_dataroot)\n",
        "testing_df = testing_df.dropna()\n",
        "testing_df = testing_df.reset_index(drop=True)\n",
        "testing_grouped = testing_df.groupby('subject_id')\n",
        "testing_df = [group for _, group in testing_grouped]\n",
        "testing_df = {value: group for value, group in testing_grouped}\n",
        "# print(testing_df[11526383])\n",
        "\n",
        "def AdvanceSplitData(data):\n",
        "  global advance_training_datalist, advance_testing_datalist, advance_output_datalist\n",
        "  global advance_trained, advance_validate, seperate_id_data, seperate_train, seperate_validate\n",
        "  global id_11526383, id_12923910, id_14699420, id_15437705, id_15642911, id_16298357\n",
        "  global id_17331999, id_17593883, id_18733920, id_18791093, id_19473413\n",
        "  # identity = ['subject_id', 'charttime', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp']\n",
        "  ##### seperate train and validate\n",
        "  data_len = len(data)\n",
        "  train_size = int(0.85 * data_len)\n",
        "\n",
        "  ##### remove train outliers\n",
        "  tmp_train = data[:train_size]\n",
        "  # print(tmp_train[0:30])\n",
        "  numeric_df = tmp_train.loc[:, ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp']] # Select only the numeric column\n",
        "  mean_values = numeric_df.mean() # Calculate the mean of each column\n",
        "  std_values = numeric_df.std()\n",
        "  mask = (numeric_df - mean_values).abs().gt(2 * std_values)\n",
        "  tmp_train = tmp_train[~mask.any(axis=1)].reset_index()\n",
        "  # print('mean_values: ')\n",
        "  # print(f'{mean_values}')\n",
        "  # print('std_values: ')\n",
        "  # print(f'{std_values}')\n",
        "  # print('tmp_train[0;30]: ')\n",
        "  # print(f'{tmp_train[0:30]}')\n",
        "  # print(f'len: {len(tmp_train)}')\n",
        "\n",
        "  ##### remove validata outliers\n",
        "  tmp_validate = data[train_size : ]\n",
        "  # print(tmp_validate[0:30])\n",
        "  numeric_df = tmp_validate.loc[:, ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp']] # Select only the numeric column\n",
        "  mean_values = numeric_df.mean() # Calculate the mean of each column\n",
        "  std_values = numeric_df.std()\n",
        "  mask = (numeric_df - mean_values).abs().gt(2 * std_values)\n",
        "  tmp_validate = tmp_validate[~mask.any(axis=1)].reset_index()\n",
        "  # print('mean_values: ')\n",
        "  # print(f'{mean_values}')\n",
        "  # print('std_values: ')\n",
        "  # print(f'{std_values}')\n",
        "  # print('tmp_validate[0;30]: ')\n",
        "  # print(f'{tmp_validate[0:30]}')\n",
        "  # print(f'len: {len(tmp_validate)}')\n",
        "\n",
        "  return tmp_train, tmp_validate\n",
        "\n",
        "def Advance_step_gradient(a_curr, b_curr, c_curr, d_curr, e_curr, f_curr, g_curr, x1, x2, x3, x4, y, learning_rate, n):\n",
        "  a_gradient = 0\n",
        "  b_gradient = 0\n",
        "  c_gradient = 0\n",
        "  d_gradient = 0\n",
        "  e_gradient = 0\n",
        "  f_gradient = 0\n",
        "  g_gradient = 0\n",
        "  # print(x1[0])\n",
        "  for i in range(n):\n",
        "    # print(\"herere\")\n",
        "    prev_case = 0\n",
        "    prev_prev_case = 0\n",
        "    if i == 0 or i == 1:\n",
        "      # calculate the median of y\n",
        "      y_median = np.median(y)\n",
        "      if i == 0:\n",
        "        prev_case = prev_prev_case = y_median\n",
        "      else:\n",
        "        prev_case = y[i-1]\n",
        "        prev_prev_case = y_median\n",
        "    else:\n",
        "      prev_case = y[i-1]\n",
        "      prev_prev_case = y[i-2]\n",
        "    y_hat = a_curr * prev_case + b_curr * prev_prev_case + c_curr * x1[i] + d_curr * x2[i] + e_curr * x3[i] + f_curr * x4[i] + g_curr\n",
        "    a_gradient = prev_case * (y[i] - (y_hat))\n",
        "    b_gradient = prev_prev_case * (y[i] - (y_hat))\n",
        "    c_gradient = x1[i] * (y[i] - (y_hat))\n",
        "    d_gradient = x2[i] * (y[i] - (y_hat))\n",
        "    e_gradient = x3[i] * (y[i] - (y_hat))\n",
        "    f_gradient = x4[i] * (y[i] - (y_hat))\n",
        "    g_gradient = (y[i] - (y_hat))\n",
        "    # update the parameters\n",
        "    a_curr += (learning_rate * a_gradient / n)\n",
        "    b_curr += (learning_rate * b_gradient / n)\n",
        "    c_curr += (learning_rate * c_gradient / n)\n",
        "    d_curr += (learning_rate * d_gradient / n)\n",
        "    e_curr += (learning_rate * e_gradient / n)\n",
        "    f_curr += (learning_rate * f_gradient / n)\n",
        "    g_curr += (learning_rate * g_gradient / n)\n",
        "    # a_new = a_curr - (learning_rate * a_gradient)\n",
        "    # b_new = b_curr - (learning_rate * b_gradient)\n",
        "    # c_new = c_curr - (learning_rate * c_gradient)\n",
        "    # d_new = d_curr - (learning_rate * d_gradient)\n",
        "    # e_new = e_curr - (learning_rate * e_gradient)\n",
        "    # f_new = f_curr - (learning_rate * f_gradient)\n",
        "    # g_new = g_curr - (learning_rate * g_gradient)\n",
        "  return a_curr, b_curr, c_curr, d_curr, e_curr, f_curr, g_curr\n",
        "  # return a_new, b_new, c_new, d_new, e_new, f_new, g_new\n",
        "\n",
        "def Advance_gradient_descent(data, learning_rate, iteration):\n",
        "  a_curr, b_curr, c_curr, d_curr, e_curr, f_curr, g_curr = 0, 0, 0, 0, 0, 0, 0\n",
        "  n = len(data)\n",
        "  for i in range(iteration):\n",
        "    a_curr, b_curr, c_curr, d_curr, e_curr, f_curr, g_curr = \\\n",
        "    Advance_step_gradient(a_curr, b_curr, c_curr, d_curr, e_curr, f_curr, g_curr, \\\n",
        "              data.iloc[:,3], data.iloc[:,4], data.iloc[:,5], data.iloc[:,6], data.iloc[:,7], learning_rate, n)\n",
        "    # print(f'ite: {i} --> {a_curr} {b_curr} {c_curr} {d_curr} {e_curr} {f_curr} {g_curr}')\n",
        "  return a_curr, b_curr, c_curr, d_curr, e_curr, f_curr, g_curr\n",
        "\n",
        "def PredictOutput(data, last_one, last_last_one, a, b, c, d, e, f, g):\n",
        "  n = len(data)\n",
        "  tmp_ans = []\n",
        "  # print(data.iloc[0][3])\n",
        "  for i in range(n):\n",
        "    if i == 0:\n",
        "      ans = a*last_one + b*last_last_one + c*data.iloc[i][2] + d*data.iloc[i][3] + e*data.iloc[i][4] + f*data.iloc[i][5] + g\n",
        "    elif i == 1:\n",
        "      ans = a*data.iloc[0][6] + b*last_one + c*data.iloc[i][2] + d*data.iloc[i][3] + e*data.iloc[i][4] + f*data.iloc[i][5] + g\n",
        "    else:\n",
        "      ans = a*data.iloc[i-1][6] + b*data.iloc[i-2][6] + c*data.iloc[i][2] + d*data.iloc[i][3] + e*data.iloc[i][4] + f*data.iloc[i][5] + g\n",
        "    tmp_ans.append([round(ans)])\n",
        "  return tmp_ans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_11526383 = training_df[11526383]\n",
        "id_11526383_train, id_11526383_validate = AdvanceSplitData(id_11526383)\n",
        "a_11526383, b_11526383, c_11526383, d_11526383, e_11526383, f_11526383, g_11526383 = \\\n",
        "Advance_gradient_descent(id_11526383_train, 0.0001, 5000)\n",
        "print(f'{a_11526383} {b_11526383} {c_11526383} {d_11526383} {e_11526383} {f_11526383} {g_11526383}')\n",
        "testing_output_11526383 = PredictOutput(testing_df[11526383], id_11526383_validate.iloc[-1, 7], id_11526383_validate.iloc[-2, 7], \\\n",
        "          a_11526383, b_11526383, c_11526383, d_11526383, e_11526383, f_11526383, g_11526383)\n",
        "print(testing_output_11526383)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKsJYG7GWTIb",
        "outputId": "c17ef637-e2e3-4d70-d8eb-af98cf9eb3d6"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16019435685029365 0.049783386290870923 -0.17551744331335242 0.7476604002478051 0.24880213469314988 0.6457490143113924 0.0008957248755104703\n",
            "[[146], [125], [126], [117], [126], [114], [113], [123], [113], [126], [122], [118], [124], [126], [118], [115], [125], [125], [112], [118]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_12923910 = training_df[12923910]\n",
        "id_12923910_train, id_12923910_validate = AdvanceSplitData(id_12923910)\n",
        "a_12923910, b_12923910, c_12923910, d_12923910, e_12923910, f_12923910, g_12923910 = \\\n",
        "Advance_gradient_descent(id_12923910_train, 0.0001, 5000)\n",
        "print(f'{a_12923910} {b_12923910} {c_12923910} {d_12923910} {e_12923910} {f_12923910} {g_12923910}')\n",
        "testing_output_12923910 = PredictOutput(testing_df[12923910], id_12923910_validate.iloc[-1, 7], id_12923910_validate.iloc[-2, 7], \\\n",
        "          a_12923910, b_12923910, c_12923910, d_12923910, e_12923910, f_12923910, g_12923910)\n",
        "print(testing_output_12923910)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWV6KkfRWW3h",
        "outputId": "0dfccd58-347a-495c-c423-52b46f12fefd"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35732871682621437 -0.1762001980675205 0.434836567112563 0.35977865223724564 0.34715704845536166 0.3666081646810294 0.011964545637834011\n",
            "[[159], [90], [113], [112], [117], [117], [122], [116], [122], [112], [118], [116], [113], [115], [133], [117], [117], [114], [127], [115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_14699420 = training_df[14699420]\n",
        "id_14699420_train, id_14699420_validate = AdvanceSplitData(id_14699420)\n",
        "a_14699420, b_14699420, c_14699420, d_14699420, e_14699420, f_14699420, g_14699420 = \\\n",
        "Advance_gradient_descent(id_14699420_train, 0.0001, 5000)\n",
        "print(f'{a_14699420} {b_14699420} {c_14699420} {d_14699420} {e_14699420} {f_14699420} {g_14699420}')\n",
        "testing_output_14699420 = PredictOutput(testing_df[14699420], id_14699420_validate.iloc[-1, 7], id_14699420_validate.iloc[-2, 7], \\\n",
        "          a_14699420, b_14699420, c_14699420, d_14699420, e_14699420, f_14699420, g_14699420)\n",
        "print(testing_output_14699420)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95qum_L-WZXm",
        "outputId": "58d3f87f-f9a1-4216-d142-1ccf13414b5b"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.26622047141637856 0.19484318354413976 0.9613572819798143 0.011855274660356852 1.0406597786963874 -0.5396621612375543 0.011951692317762679\n",
            "[[127], [83], [62], [63], [61], [57], [64], [66], [64], [63], [66], [64], [69], [70], [63], [72], [72], [67], [70], [60]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_15437705 = training_df[15437705]\n",
        "id_15437705_train, id_15437705_validate = AdvanceSplitData(id_15437705)\n",
        "a_15437705, b_15437705, c_15437705, d_15437705, e_15437705, f_15437705, g_15437705 = \\\n",
        "Advance_gradient_descent(id_15437705_train, 0.0001, 5000)\n",
        "print(f'{a_15437705} {b_15437705} {c_15437705} {d_15437705} {e_15437705} {f_15437705} {g_15437705}')\n",
        "testing_output_15437705 = PredictOutput(testing_df[15437705], id_15437705_validate.iloc[-1, 7], id_15437705_validate.iloc[-2, 7], \\\n",
        "          a_15437705, b_15437705, c_15437705, d_15437705, e_15437705, f_15437705, g_15437705)\n",
        "print(testing_output_15437705)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNeK1TnjWdf6",
        "outputId": "1ccd2f19-6442-44b2-a055-8fa07c1311cb"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22690266947405588 0.22289740338965405 -0.4293212932516622 -0.5104758809288608 1.5294263934006247 1.3185025623569997 -0.0021481838086891175\n",
            "[[149], [115], [88], [90], [66], [68], [68], [84], [81], [83], [86], [78], [69], [73], [77], [77], [77], [81], [68], [71]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_15642911 = training_df[15642911]\n",
        "id_15642911_train, id_15642911_validate = AdvanceSplitData(id_15642911)\n",
        "a_15642911, b_15642911, c_15642911, d_15642911, e_15642911, f_15642911, g_15642911 = \\\n",
        "Advance_gradient_descent(id_15642911_train, 0.0001, 5000)\n",
        "print(f'{a_15642911} {b_15642911} {c_15642911} {d_15642911} {e_15642911} {f_15642911} {g_15642911}')\n",
        "testing_output_15642911 = PredictOutput(testing_df[15642911], id_15642911_validate.iloc[-1, 7], id_15642911_validate.iloc[-2, 7], \\\n",
        "          a_15642911, b_15642911, c_15642911, d_15642911, e_15642911, f_15642911, g_15642911)\n",
        "print(testing_output_15642911)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN24qooPWfdL",
        "outputId": "95d6d944-8f5d-4179-edd5-5f5347baca50"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2033836636190005 0.04221703645872168 0.6810408686549654 -0.019297732068872163 0.5684658670950989 0.2086015894736776 0.0037318194415047476\n",
            "[[122], [100], [97], [97], [94], [94], [95], [95], [96], [95], [94], [96], [96], [96], [95], [95], [95], [95], [96], [96]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_16298357 = training_df[16298357]\n",
        "id_16298357_train, id_16298357_validate = AdvanceSplitData(id_16298357)\n",
        "a_16298357, b_16298357, c_16298357, d_16298357, e_16298357, f_16298357, g_16298357 = \\\n",
        "Advance_gradient_descent(id_16298357_train, 0.0001, 5000)\n",
        "print(f'{a_16298357} {b_16298357} {c_16298357} {d_16298357} {e_16298357} {f_16298357} {g_16298357}')\n",
        "testing_output_16298357 = PredictOutput(testing_df[16298357], id_16298357_validate.iloc[-1, 7], id_16298357_validate.iloc[-2, 7], \\\n",
        "          a_16298357, b_16298357, c_16298357, d_16298357, e_16298357, f_16298357, g_16298357)\n",
        "print(testing_output_16298357)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l-pxgNVWgCe",
        "outputId": "8536d06b-6645-4df7-fa0d-7b321cb98ec8"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20065728717162282 0.016902964875832108 0.7463791240118598 0.17840771272963601 -0.2769933475098609 0.2181655033798242 -0.0012083441473363676\n",
            "[[132], [108], [107], [107], [106], [107], [109], [107], [105], [105], [111], [105], [105], [107], [107], [108], [106], [106], [108], [105]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_17331999 = training_df[17331999]\n",
        "id_17331999_train, id_17331999_validate = AdvanceSplitData(id_17331999)\n",
        "a_17331999, b_17331999, c_17331999, d_17331999, e_17331999, f_17331999, g_17331999 = \\\n",
        "Advance_gradient_descent(id_17331999_train, 0.0001, 5000)\n",
        "print(f'{a_17331999} {b_17331999} {c_17331999} {d_17331999} {e_17331999} {f_17331999} {g_17331999}')\n",
        "testing_output_17331999 = PredictOutput(testing_df[17331999], id_17331999_validate.iloc[-1, 7], id_17331999_validate.iloc[-2, 7], \\\n",
        "          a_17331999, b_17331999, c_17331999, d_17331999, e_17331999, f_17331999, g_17331999)\n",
        "print(testing_output_17331999)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eQJfJoJWh6W",
        "outputId": "c851403e-de41-4f2d-e011-f9aa85cfc0d1"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.033357618414286916 -0.0011010779349643759 0.35238136187668373 0.12828376839754463 0.3010032213145025 0.6594320846607825 0.008147012300865855\n",
            "[[118], [112], [116], [118], [115], [113], [112], [112], [112], [113], [114], [116], [111], [115], [115], [113], [112], [117], [114], [112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_17593883 = training_df[17593883]\n",
        "id_17593883_train, id_17593883_validate = AdvanceSplitData(id_17593883)\n",
        "a_17593883, b_17593883, c_17593883, d_17593883, e_17593883, f_17593883, g_17593883 = \\\n",
        "Advance_gradient_descent(id_17593883_train, 0.0001, 10000)\n",
        "print(f'{a_17593883} {b_17593883} {c_17593883} {d_17593883} {e_17593883} {f_17593883} {g_17593883}')\n",
        "testing_output_17593883 = PredictOutput(testing_df[17593883], id_17593883_validate.iloc[-1, 7], id_17593883_validate.iloc[-2, 7], \\\n",
        "          a_17593883, b_17593883, c_17593883, d_17593883, e_17593883, f_17593883, g_17593883)\n",
        "print(testing_output_17593883)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGMgEzI-WkWR",
        "outputId": "e2fbf93e-ae78-44e7-f8ce-953de467ef08"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15596121000600616 -0.08799883738602925 0.7882036547338189 0.03782486655838349 0.7313088873362444 0.2611323247723572 0.0015016455967439316\n",
            "[[126], [108], [120], [118], [119], [119], [117], [124], [123], [122], [115], [118], [118], [118], [120], [116], [117], [125], [121], [121]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_18733920 = training_df[18733920]\n",
        "id_18733920_train, id_18733920_validate = AdvanceSplitData(id_18733920)\n",
        "a_18733920, b_18733920, c_18733920, d_18733920, e_18733920, f_18733920, g_18733920 = \\\n",
        "Advance_gradient_descent(id_18733920_train, 0.0001, 5000)\n",
        "print(f'{a_18733920} {b_18733920} {c_18733920} {d_18733920} {e_18733920} {f_18733920} {g_18733920}')\n",
        "testing_output_18733920 = PredictOutput(testing_df[18733920], id_18733920_validate.iloc[-1, 7], id_18733920_validate.iloc[-2, 7], \\\n",
        "          a_18733920, b_18733920, c_18733920, d_18733920, e_18733920, f_18733920, g_18733920)\n",
        "print(testing_output_18733920)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW1sq-2mWmpU",
        "outputId": "881b6f55-9844-4b99-b516-e31064b97caa"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1626956300747355 -0.034720823890477016 0.7419951327531851 0.257466407025522 -0.7624202276621087 0.37173054513739034 -0.009153350117932894\n",
            "[[142], [110], [118], [119], [123], [125], [124], [119], [121], [126], [120], [118], [119], [119], [120], [117], [117], [121], [118], [117]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_18791093 = training_df[18791093]\n",
        "id_18791093_train, id_18791093_validate = AdvanceSplitData(id_18791093)\n",
        "a_18791093, b_18791093, c_18791093, d_18791093, e_18791093, f_18791093, g_18791093 = \\\n",
        "Advance_gradient_descent(id_18791093_train, 0.0001, 5000)\n",
        "print(f'{a_18791093} {b_18791093} {c_18791093} {d_18791093} {e_18791093} {f_18791093} {g_18791093}')\n",
        "testing_output_18791093 = PredictOutput(testing_df[18791093], id_18791093_validate.iloc[-1, 7], id_18791093_validate.iloc[-2, 7], \\\n",
        "          a_18791093, b_18791093, c_18791093, d_18791093, e_18791093, f_18791093, g_18791093)\n",
        "print(testing_output_18791093)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIi1R5oZWpS5",
        "outputId": "c958b6e7-6721-41f5-f571-f6ad605f78da"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.057826111460173205 0.04967735865038672 0.6859503850257181 -0.28096574404922886 0.20474845202822567 0.7440226147915365 0.008949606097201466\n",
            "[[132], [124], [110], [115], [123], [121], [113], [117], [120], [111], [126], [118], [120], [125], [117], [119], [115], [115], [113], [122]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_19473413 = training_df[19473413]\n",
        "id_19473413_train, id_19473413_validate = AdvanceSplitData(id_19473413)\n",
        "a_19473413, b_19473413, c_19473413, d_19473413, e_19473413, f_19473413, g_19473413 = \\\n",
        "Advance_gradient_descent(id_19473413_train, 0.0001, 5000)\n",
        "print(f'{a_19473413} {b_19473413} {c_19473413} {d_19473413} {e_19473413} {f_19473413} {g_19473413}')\n",
        "testing_output_19473413 = PredictOutput(testing_df[19473413], id_19473413_validate.iloc[-1, 7], id_19473413_validate.iloc[-2, 7], \\\n",
        "          a_19473413, b_19473413, c_19473413, d_19473413, e_19473413, f_19473413, g_19473413)\n",
        "print(testing_output_19473413)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otF-LKg0WrXC",
        "outputId": "5a096e12-a9d4-45c2-de93-92ae207f398f"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2520520003541147 0.15261636473304246 0.29080222134905226 0.07266474709300509 0.3697072793942461 0.3478652468328612 0.001823867403830214\n",
            "[[134], [97], [73], [73], [75], [74], [75], [77], [77], [73], [75], [76], [77], [74], [76], [75], [76], [75], [73], [76]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "advance_output_datalist.extend(testing_output_11526383)\n",
        "advance_output_datalist.extend(testing_output_12923910)\n",
        "advance_output_datalist.extend(testing_output_14699420)\n",
        "advance_output_datalist.extend(testing_output_15437705)\n",
        "advance_output_datalist.extend(testing_output_15642911)\n",
        "advance_output_datalist.extend(testing_output_16298357)\n",
        "advance_output_datalist.extend(testing_output_17331999)\n",
        "advance_output_datalist.extend(testing_output_17593883)\n",
        "advance_output_datalist.extend(testing_output_18733920)\n",
        "advance_output_datalist.extend(testing_output_18791093)\n",
        "advance_output_datalist.extend(testing_output_19473413)\n",
        "print(advance_output_datalist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAibXcBzfj0u",
        "outputId": "a9ca51ae-335d-4968-eb30-404e429ab391"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[146], [125], [126], [117], [126], [114], [113], [123], [113], [126], [122], [118], [124], [126], [118], [115], [125], [125], [112], [118], [159], [90], [113], [112], [117], [117], [122], [116], [122], [112], [118], [116], [113], [115], [133], [117], [117], [114], [127], [115], [127], [83], [62], [63], [61], [57], [64], [66], [64], [63], [66], [64], [69], [70], [63], [72], [72], [67], [70], [60], [149], [115], [88], [90], [66], [68], [68], [84], [81], [83], [86], [78], [69], [73], [77], [77], [77], [81], [68], [71], [122], [100], [97], [97], [94], [94], [95], [95], [96], [95], [94], [96], [96], [96], [95], [95], [95], [95], [96], [96], [132], [108], [107], [107], [106], [107], [109], [107], [105], [105], [111], [105], [105], [107], [107], [108], [106], [106], [108], [105], [118], [112], [116], [118], [115], [113], [112], [112], [112], [113], [114], [116], [111], [115], [115], [113], [112], [117], [114], [112], [126], [108], [120], [118], [119], [119], [117], [124], [123], [122], [115], [118], [118], [118], [120], [116], [117], [125], [121], [121], [142], [110], [118], [119], [123], [125], [124], [119], [121], [126], [120], [118], [119], [119], [120], [117], [117], [121], [118], [117], [132], [124], [110], [115], [123], [121], [113], [117], [120], [111], [126], [118], [120], [125], [117], [119], [115], [115], [113], [122], [134], [97], [73], [73], [75], [74], [75], [77], [77], [73], [75], [76], [77], [74], [76], [75], [76], [75], [73], [76]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### print MAPE to make sure the correctness"
      ],
      "metadata": {
        "id": "d5W0h1E38mUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test validation set MAPE\n",
        "def testValidationMape(data, a, b, c, d, e, f, g):\n",
        "  mapeVal = 0\n",
        "  tmpAns = []\n",
        "  n = len(data)\n",
        "  for i in range(2,n):\n",
        "    ggg = a*data.iloc[i-1][7] + b*data.iloc[i-2][7] + c*data.iloc[i][3] + d*data.iloc[i][4] + e*data.iloc[i][5] + f*data.iloc[i][6] + g\n",
        "    tmpAns.append(ggg)\n",
        "\n",
        "  for i in range(len(tmpAns)):\n",
        "    mapeVal += abs((data.iloc[i+2][7] - round(tmpAns[i])) / data.iloc[i+2][7])\n",
        "\n",
        "  print(mapeVal / len(tmpAns) * 100)\n",
        "  # print(mapeVal / range(len(tmpAns)))\n",
        "\n",
        "testValidationMape(id_11526383_validate, a_11526383, b_11526383, c_11526383, d_11526383, e_11526383, f_11526383, g_11526383)\n",
        "testValidationMape(id_12923910_validate, a_12923910, b_12923910, c_12923910, d_12923910, e_12923910, f_12923910, g_12923910)\n",
        "testValidationMape(id_14699420_validate, a_14699420, b_14699420, c_14699420, d_14699420, e_14699420, f_14699420, g_14699420)\n",
        "testValidationMape(id_15437705_validate, a_15437705, b_15437705, c_15437705, d_15437705, e_15437705, f_15437705, g_15437705)\n",
        "testValidationMape(id_15642911_validate, a_15642911, b_15642911, c_15642911, d_15642911, e_15642911, f_15642911, g_15642911)\n",
        "testValidationMape(id_16298357_validate, a_16298357, b_16298357, c_16298357, d_16298357, e_16298357, f_16298357, g_16298357)\n",
        "testValidationMape(id_17331999_validate, a_17331999, b_17331999, c_17331999, d_17331999, e_17331999, f_17331999, g_17331999)\n",
        "testValidationMape(id_17593883_validate, a_17593883, b_17593883, c_17593883, d_17593883, e_17593883, f_17593883, g_17593883)\n",
        "testValidationMape(id_18733920_validate, a_18733920, b_18733920, c_18733920, d_18733920, e_18733920, f_18733920, g_18733920)\n",
        "testValidationMape(id_18791093_validate, a_18791093, b_18791093, c_18791093, d_18791093, e_18791093, f_18791093, g_18791093)\n",
        "testValidationMape(id_19473413_validate, a_19473413, b_19473413, c_19473413, d_19473413, e_19473413, f_19473413, g_19473413)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWGo-dRO9lks",
        "outputId": "f110ffa8-d60b-434e-a734-e90b89ae5de9"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.963988544141817\n",
            "7.9227518644384\n",
            "8.816854719952305\n",
            "9.372911138467622\n",
            "6.022259201090916\n",
            "9.481848143501349\n",
            "7.573378516034415\n",
            "13.060467992337626\n",
            "11.782939643990673\n",
            "10.936767126067457\n",
            "10.267627171278768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQs6JEDqYnJt"
      },
      "source": [
        "### Output your Prediction\n",
        "\n",
        ">your filename should be **hw1_advanced.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "ym3gp47BYnJt"
      },
      "outputs": [],
      "source": [
        "with open(advance_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in advance_output_datalist:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtgCJU7FPeJL"
      },
      "source": [
        "# Report *(5%)*\n",
        "\n",
        "Report should be submitted as a pdf file **hw1_report.pdf**\n",
        "\n",
        "*   Briefly describe the difficulty you encountered\n",
        "*   Summarize your work and your reflections\n",
        "*   No more than one page\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlEE53_MPf4W"
      },
      "source": [
        "# Save the Code File\n",
        "Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}